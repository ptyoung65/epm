# LLM Integration Guide - AIRIS-MON AIOps System\n\n## ê°œìš”\n\nAIRIS-MON ì‹œìŠ¤í…œì— í†µí•©ëœ í¬ê´„ì ì¸ LLM(Large Language Model) ì‹œìŠ¤í…œìœ¼ë¡œ, Ollama Gemma 3.1Bë¥¼ ì£¼ìš” ë¡œì»¬ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³  ì™¸ë¶€ LLM ì œê³µìë“¤ê³¼ì˜ í†µí•©ì„ ì§€ì›í•©ë‹ˆë‹¤.\n\n## ğŸš€ ì£¼ìš” íŠ¹ì§•\n\n### 1. Multi-LLM ì§€ì›\n- **Primary**: Ollama Gemma 3.1B (ë¡œì»¬)\n- **Fallback**: Google Gemini Pro, OpenAI GPT-4, Anthropic Claude\n- **ì§€ëŠ¥í˜• ë¼ìš°íŒ…**: ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ\n- **ë¡œë“œ ë°¸ëŸ°ì‹±**: ì„±ëŠ¥ ê¸°ë°˜ ë™ì  ë¡œë“œ ë¶„ì‚°\n\n### 2. í•œêµ­ì–´ íŠ¹í™” ìµœì í™”\n- **ì „ì²˜ë¦¬**: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ê·œí™” ë° ìµœì í™”\n- **í›„ì²˜ë¦¬**: ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ ë° ì¼ê´€ì„± ë³´ì¥\n- **í’ˆì§ˆ ê²€ì¦**: í•œêµ­ì–´ í’ˆì§ˆ ìë™ í‰ê°€\n- **ë¬¸ë§¥ ì¸ì‹**: í•œêµ­ ë¬¸í™” ë° ê´€ìŠµ ê³ ë ¤\n\n### 3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°\n- **Server-Sent Events**: ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n- **Progressive Loading**: ì ì§„ì  ì‘ë‹µ ë¡œë”©\n- **ì—ëŸ¬ í•¸ë“¤ë§**: ê²¬ê³ í•œ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬ ì²˜ë¦¬\n\n## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Web Client    â”‚â—„â”€â”€â–ºâ”‚  Multi-LLM       â”‚â—„â”€â”€â–ºâ”‚  LLM Config     â”‚\nâ”‚                 â”‚    â”‚  Router          â”‚    â”‚  Manager        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                â”‚                        â”‚\n                                â–¼                        â–¼\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚ Korean Language  â”‚    â”‚ Health Monitor  â”‚\n                    â”‚ Processor        â”‚    â”‚ & Metrics       â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                â”‚\n                                â–¼\n        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â”‚   Ollama    â”‚     Gemini       â”‚   OpenAI    â”‚   Claude    â”‚\n        â”‚ Gemma 3.1B  â”‚      Pro         â”‚    GPT-4    â”‚   Sonnet    â”‚\n        â”‚   (Local)   â”‚    (Cloud)       â”‚  (Cloud)    â”‚  (Cloud)    â”‚\n        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## ğŸ“‹ API ì—”ë“œí¬ì¸íŠ¸\n\n### 1. ì±„íŒ… ì™„ì„± API\n```http\nPOST /api/llm/chat\nContent-Type: application/json\n\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. AIRIS-MON ì‹œìŠ¤í…œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n    }\n  ],\n  \"taskType\": \"korean-chat\",\n  \"providerId\": \"ollama\",\n  \"options\": {\n    \"temperature\": 0.7,\n    \"formality\": \"formal\"\n  },\n  \"stream\": false\n}\n```\n\n**ì‘ë‹µ:**\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"AIRIS-MONì€ í¬ê´„ì ì¸ AIOps ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤...\"\n    },\n    \"usage\": {\n      \"prompt_tokens\": 25,\n      \"completion_tokens\": 150,\n      \"total_tokens\": 175\n    }\n  },\n  \"taskType\": \"korean-chat\",\n  \"provider\": \"ollama\"\n}\n```\n\n### 2. ë°ì´í„° ë¶„ì„ API\n```http\nPOST /api/llm/analyze\nContent-Type: application/json\n\n{\n  \"data\": {\n    \"cpu_usage\": [75, 82, 90, 95, 88],\n    \"memory_usage\": [60, 65, 70, 75, 72],\n    \"response_time\": [120, 150, 200, 300, 180]\n  },\n  \"analysisType\": \"performance\",\n  \"language\": \"korean\",\n  \"providerId\": \"ollama\"\n}\n```\n\n### 3. ëª¨ë¸ ëª©ë¡ ì¡°íšŒ\n```http\nGET /api/llm/models\n```\n\n**ì‘ë‹µ:**\n```json\n{\n  \"success\": true,\n  \"models\": [\n    {\n      \"id\": \"ollama\",\n      \"name\": \"Ollama Gemma 3.1B\",\n      \"type\": \"local\",\n      \"status\": \"active\",\n      \"health\": {\n        \"status\": \"healthy\",\n        \"responseTime\": 45\n      },\n      \"priority\": 1,\n      \"cost_per_token\": 0,\n      \"korean_optimized\": true\n    }\n  ],\n  \"currentProvider\": \"ollama\"\n}\n```\n\n### 4. ì œê³µì ì „í™˜\n```http\nPOST /api/llm/switch\nContent-Type: application/json\n\n{\n  \"providerId\": \"gemini\"\n}\n```\n\n### 5. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n```http\nGET /api/llm/health\n```\n\n### 6. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n```http\nPOST /api/llm/benchmark\nContent-Type: application/json\n\n{\n  \"testPrompt\": \"í•œêµ­ì–´ë¡œ ì•ˆë…•í•˜ì„¸ìš”ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”\"\n}\n```\n\n### 7. í•œêµ­ì–´ í’ˆì§ˆ í‰ê°€\n```http\nPOST /api/llm/korean-quality\nContent-Type: application/json\n\n{\n  \"text\": \"í‰ê°€í•  í•œêµ­ì–´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤\"\n}\n```\n\n## ğŸ”§ ì„¤ì • ë° ì„¤ì¹˜\n\n### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ì„¤ì •ì„ ì¶”ê°€:\n\n```bash\n# Ollama ì„¤ì •\nOLLAMA_ENDPOINT=http://localhost:11434\nOLLAMA_MODEL=gemma2:3b\n\n# ì™¸ë¶€ LLM API í‚¤\nGEMINI_API_KEY=your_gemini_api_key\nOPENAI_API_KEY=your_openai_api_key\nCLAUDE_API_KEY=your_claude_api_key\n\n# ê¸°ë³¸ ì„¤ì •\nDEFAULT_LLM_PROVIDER=ollama\nPREFER_LOCAL_LLM=true\nDEFAULT_FORMALITY=formal\n```\n\n### 2. Ollama ì„¤ì¹˜ ë° Gemma 3.1B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n\n```bash\n# Ollama ì„¤ì¹˜ (Linux/macOS)\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Gemma 3.1B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\nollama pull gemma2:3b\n\n# Ollama ì„œë¹„ìŠ¤ ì‹œì‘\nollama serve\n```\n\n### 3. ì˜ì¡´ì„± ì„¤ì¹˜\n\n```bash\nnpm install\n# ë˜ëŠ”\nyarn install\n```\n\n### 4. ì‹œìŠ¤í…œ ì‹œì‘\n\n```bash\nnpm start\n# ë˜ëŠ” ê°œë°œ ëª¨ë“œ\nnpm run dev\n```\n\n## ğŸ¯ ì‚¬ìš© ì˜ˆì œ\n\n### 1. JavaScript í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ\n\n```javascript\n// ì¼ë°˜ ì±„íŒ…\nconst response = await fetch('/api/llm/chat', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    messages: [\n      {\n        role: 'user',\n        content: 'ì„œë²„ ì„±ëŠ¥ ë¬¸ì œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”'\n      }\n    ],\n    taskType: 'analysis',\n    options: {\n      temperature: 0.3,\n      formality: 'formal'\n    }\n  })\n});\n\nconst data = await response.json();\nconsole.log(data.data.message.content);\n```\n\n### 2. ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì˜ˆì œ\n\n```javascript\n// ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…\nconst eventSource = new EventSource('/api/llm/chat');\n\neventSource.onmessage = function(event) {\n  const data = JSON.parse(event.data);\n  \n  if (data.content) {\n    document.getElementById('response').innerHTML += data.content;\n  }\n  \n  if (data.done) {\n    eventSource.close();\n    console.log('ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ');\n  }\n};\n\neventSource.onerror = function(event) {\n  console.error('ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:', event);\n  eventSource.close();\n};\n```\n\n### 3. ì‹œìŠ¤í…œ ë¶„ì„ ì˜ˆì œ\n\n```javascript\n// ì„±ëŠ¥ ë°ì´í„° ë¶„ì„\nconst analysisResponse = await fetch('/api/llm/analyze', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    data: {\n      metrics: {\n        cpu: [85, 90, 95, 88],\n        memory: [70, 75, 80, 78],\n        disk_io: [120, 150, 180, 160]\n      },\n      errors: [\n        {\n          timestamp: '2024-01-15T10:30:00Z',\n          level: 'ERROR',\n          message: 'Database connection timeout'\n        }\n      ]\n    },\n    analysisType: 'performance',\n    language: 'korean'\n  })\n});\n\nconst analysis = await analysisResponse.json();\nconsole.log(analysis.analysis);\n```\n\n## ğŸ”„ ì‘ì—… ìœ í˜• (Task Types)\n\n### 1. korean-chat\n- **ìš©ë„**: ì¼ë°˜ì ì¸ í•œêµ­ì–´ ëŒ€í™”\n- **ìµœì í™”**: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„\n- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: í•œêµ­ì–´ ëŒ€í™” ì „ë¬¸ê°€\n\n### 2. code-generation\n- **ìš©ë„**: ì½”ë“œ ìƒì„± ë° í”„ë¡œê·¸ë˜ë° ë„ì›€\n- **ìµœì í™”**: í•œêµ­ì–´ ì£¼ì„ í¬í•¨ ì½”ë“œ\n- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: í”„ë¡œê·¸ë˜ë° ì „ë¬¸ê°€\n\n### 3. analysis\n- **ìš©ë„**: ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ\n- **ìµœì í™”**: êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼\n- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€\n\n### 4. translation\n- **ìš©ë„**: ë²ˆì—­ ì‘ì—…\n- **ìµœì í™”**: ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­\n- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: ì „ë¬¸ ë²ˆì—­ê°€\n\n### 5. tech-support\n- **ìš©ë„**: ê¸°ìˆ  ì§€ì› ë° ë¬¸ì œ í•´ê²°\n- **ìµœì í™”**: ë‹¨ê³„ë³„ í•´ê²° ë°©ì•ˆ\n- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: ê¸°ìˆ  ì§€ì› ì „ë¬¸ê°€\n\n## ğŸ“Š ì„±ëŠ¥ ìµœì í™”\n\n### 1. ëª¨ë¸ ì„ íƒ ì „ëµ\n- **ë¡œì»¬ ìš°ì„ **: Ollama Gemma 3.1B ìš°ì„  ì‚¬ìš©\n- **ì‘ì—…ë³„ ìµœì í™”**: ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ\n- **ë¹„ìš© ê³ ë ¤**: í† í°ë‹¹ ë¹„ìš© ê¸°ë°˜ ì„ íƒ\n- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‘ë‹µ ì‹œê°„ ë° í’ˆì§ˆ ê¸°ë°˜ ì„ íƒ\n\n### 2. ìºì‹± ì „ëµ\n- **ì‘ë‹µ ìºì‹±**: ë¹ˆë²ˆí•œ ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±\n- **ëª¨ë¸ ìƒíƒœ ìºì‹±**: ëª¨ë¸ ìƒíƒœ ì •ë³´ ìºì‹±\n- **í•œêµ­ì–´ ì „ì²˜ë¦¬ ìºì‹±**: ì „ì²˜ë¦¬ ê²°ê³¼ ìºì‹±\n\n### 3. ë¡œë“œ ë°¸ëŸ°ì‹±\n- **ìš”ì²­ ë¶„ì‚°**: ì—¬ëŸ¬ ì œê³µì ê°„ ìš”ì²­ ë¶„ì‚°\n- **í—¬ìŠ¤ ì²´í¬**: ì‹¤ì‹œê°„ ì œê³µì ìƒíƒœ ëª¨ë‹ˆí„°ë§\n- **ìë™ ë³µêµ¬**: ì‹¤íŒ¨í•œ ì œê³µì ìë™ ë³µêµ¬\n\n## ğŸ›¡ï¸ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­\n\n### 1. API í‚¤ ê´€ë¦¬\n- **í™˜ê²½ ë³€ìˆ˜**: API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬\n- **ì•”í˜¸í™”**: ì €ì¥ëœ í‚¤ ì•”í˜¸í™”\n- **ì ‘ê·¼ ì œì–´**: API í‚¤ ì ‘ê·¼ ê¶Œí•œ ì œí•œ\n\n### 2. ìš”ì²­ ì œí•œ\n- **Rate Limiting**: ìš”ì²­ ë¹ˆë„ ì œí•œ\n- **í† í° ì œí•œ**: ìµœëŒ€ í† í° ìˆ˜ ì œí•œ\n- **ì‚¬ìš©ì ì¸ì¦**: ì‚¬ìš©ìë³„ ì ‘ê·¼ ì œì–´\n\n### 3. ë°ì´í„° ë³´ì•ˆ\n- **ì „ì†¡ ì•”í˜¸í™”**: HTTPS ì‚¬ìš©\n- **ë¡œê·¸ ê´€ë¦¬**: ë¯¼ê°í•œ ì •ë³´ ë¡œê·¸ ì œì™¸\n- **ë°ì´í„° ìµœì†Œí™”**: í•„ìš”í•œ ë°ì´í„°ë§Œ ì „ì†¡\n\n## ğŸ” ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…\n\n### 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­\n- **ì‘ë‹µ ì‹œê°„**: í‰ê·  ì‘ë‹µ ì‹œê°„ ì¶”ì \n- **í† í° ì‚¬ìš©ëŸ‰**: í† í° ì†Œë¹„ íŒ¨í„´ ë¶„ì„\n- **ì˜¤ë¥˜ìœ¨**: ì˜¤ë¥˜ ë°œìƒ ë¹ˆë„ ëª¨ë‹ˆí„°ë§\n- **ì œê³µì ìƒíƒœ**: ê° ì œê³µìë³„ ìƒíƒœ ì¶”ì \n\n### 2. í’ˆì§ˆ ë©”íŠ¸ë¦­\n- **í•œêµ­ì–´ í’ˆì§ˆ ì ìˆ˜**: ì‘ë‹µ í’ˆì§ˆ í‰ê°€\n- **ì‚¬ìš©ì ë§Œì¡±ë„**: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\n- **ì •í™•ë„**: ì‘ë‹µ ì •í™•ë„ ì¸¡ì •\n\n### 3. ìš´ì˜ ë©”íŠ¸ë¦­\n- **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤**: CPU, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n- **ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰**: ëŒ€ì—­í­ ì‚¬ìš© íŒ¨í„´\n- **ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰**: ìºì‹œ ë° ë¡œê·¸ ì‚¬ìš©ëŸ‰\n\n## ğŸš¨ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n\n### 1. Ollama ì—°ê²° ë¬¸ì œ\n```bash\n# Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸\nsudo systemctl status ollama\n\n# Ollama ì„œë¹„ìŠ¤ ì¬ì‹œì‘\nsudo systemctl restart ollama\n\n# ëª¨ë¸ ëª©ë¡ í™•ì¸\nollama list\n\n# Gemma ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ\nollama pull gemma2:3b\n```\n\n### 2. ì™¸ë¶€ API ì—°ê²° ë¬¸ì œ\n- **API í‚¤ ê²€ì¦**: API í‚¤ ìœ íš¨ì„± í™•ì¸\n- **ë„¤íŠ¸ì›Œí¬ ì—°ê²°**: ì™¸ë¶€ ì„œë¹„ìŠ¤ ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸\n- **ìš”ì²­ ì œí•œ**: API ì‚¬ìš©ëŸ‰ í•œë„ í™•ì¸\n\n### 3. ì„±ëŠ¥ ë¬¸ì œ\n- **ë¡œë“œ ë°¸ëŸ°ì‹±**: ìš”ì²­ ë¶„ì‚° í™•ì¸\n- **ìºì‹œ ìƒíƒœ**: ìºì‹œ ì ì¤‘ë¥  í™•ì¸\n- **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰**: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§\n\n## ğŸ“š ì¶”ê°€ ìë£Œ\n\n- [Ollama ê³µì‹ ë¬¸ì„œ](https://ollama.ai/docs)\n- [Google Gemini API ë¬¸ì„œ](https://developers.generativeai.google/docs)\n- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)\n- [Anthropic Claude API ë¬¸ì„œ](https://docs.anthropic.com/)\n- [AIRIS-MON ì‹œìŠ¤í…œ ë¬¸ì„œ](./README.md)\n\n## ğŸ”„ ì—…ë°ì´íŠ¸ ë° ìœ ì§€ë³´ìˆ˜\n\n### 1. ëª¨ë¸ ì—…ë°ì´íŠ¸\n```bash\n# Gemma ëª¨ë¸ ì—…ë°ì´íŠ¸\nollama pull gemma2:3b\n\n# ìƒˆ ëª¨ë¸ ë²„ì „ í™•ì¸\nollama list\n```\n\n### 2. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸\n```bash\n# ì˜ì¡´ì„± ì—…ë°ì´íŠ¸\nnpm update\n\n# ì‹œìŠ¤í…œ ì¬ì‹œì‘\nnpm restart\n```\n\n### 3. ì„¤ì • ë°±ì—…\n```bash\n# ì„¤ì • íŒŒì¼ ë°±ì—…\ncp .env .env.backup\ncp -r src/llm/ backup/llm/\n```\n\n---\n\n**ë²„ì „**: 1.0.0  \n**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024-01-15  \n**ì‘ì„±ì**: AIRIS-MON Development Team\n