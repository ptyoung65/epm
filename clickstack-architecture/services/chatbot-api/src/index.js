const express = require('express');
const cors = require('cors');
const { Pool } = require('pg');
// const Redis = require('redis'); // Temporarily disabled
const OpenAI = require('openai');
const Anthropic = require('@anthropic-ai/sdk');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const axios = require('axios');
const rateLimit = require('express-rate-limit');

const app = express();
const port = process.env.PORT || 3013;

// Middleware
app.use(cors());
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true }));

// Rate limiting
const chatbotLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15ë¶„
  max: 100, // ì‚¬ìš©ìžë‹¹ 15ë¶„ì— 100ê°œ ìš”ì²­ ì œí•œ
  message: { error: 'ë„ˆë¬´ ë§Žì€ ìš”ì²­ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' }
});

app.use('/api/chatbot', chatbotLimiter);

// Database connection
const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: process.env.DB_PORT || 5432,
  database: process.env.DB_NAME || 'airis_epm',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || 'postgres',
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

// Redis connection disabled temporarily
let redisClient = null;

// LLM Clients initialization
const llmClients = {
  openai: null,
  claude: null,
  gemini: null,
  ollama: null
};

// Initialize database tables
async function initializeDatabase() {
  try {
    console.log('Creating chatbot_configs table...');
    // Chatbot configurations table
    await pool.query(`
      CREATE TABLE IF NOT EXISTS chatbot_configs (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100) NOT NULL UNIQUE,
        description TEXT,
        provider VARCHAR(50) NOT NULL,
        model VARCHAR(100) NOT NULL,
        system_prompt TEXT,
        temperature NUMERIC(3,2) DEFAULT 0.7,
        max_tokens INTEGER DEFAULT 2000,
        is_active BOOLEAN DEFAULT true,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);
    console.log('âœ“ chatbot_configs table created');

    console.log('Creating api_configs table...');
    // API configurations table
    await pool.query(`
      CREATE TABLE IF NOT EXISTS api_configs (
        id SERIAL PRIMARY KEY,
        provider VARCHAR(50) NOT NULL UNIQUE,
        api_key TEXT NOT NULL,
        base_url VARCHAR(500),
        is_active BOOLEAN DEFAULT true,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);
    console.log('âœ“ api_configs table created');

    console.log('Creating chat_history table...');
    // Chat history table
    await pool.query(`
      CREATE TABLE IF NOT EXISTS chat_history (
        id SERIAL PRIMARY KEY,
        session_id VARCHAR(100) NOT NULL,
        user_id VARCHAR(100),
        chatbot_id INTEGER REFERENCES chatbot_configs(id),
        user_message TEXT NOT NULL,
        bot_response TEXT NOT NULL,
        context_info JSONB,
        response_time_ms INTEGER,
        tokens_used INTEGER,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);
    console.log('âœ“ chat_history table created');

    // Create indexes for chat_history
    await pool.query(`CREATE INDEX IF NOT EXISTS idx_chat_history_session_id ON chat_history(session_id)`);
    await pool.query(`CREATE INDEX IF NOT EXISTS idx_chat_history_user_id ON chat_history(user_id)`);
    await pool.query(`CREATE INDEX IF NOT EXISTS idx_chat_history_created_at ON chat_history(created_at)`);

    // Initialize default chatbots if none exist
    const { rows } = await pool.query('SELECT COUNT(*) as count FROM chatbot_configs');
    if (parseInt(rows[0].count) === 0) {
      await initializeDefaultChatbots();
    }

    console.log('Database initialized successfully');
  } catch (error) {
    console.error('Database initialization error:', error);
  }
}

// Initialize default chatbots
async function initializeDefaultChatbots() {
  const defaultBots = [
    {
      name: 'AIRIS ì„±ëŠ¥ ë¶„ì„ê°€',
      description: 'J2EE, WAS, ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì „ë¬¸ ì±—ë´‡',
      provider: 'openai',
      model: 'gpt-4o-mini',
      system_prompt: `ë‹¹ì‹ ì€ AIRIS EPM (Enterprise Performance Management) ì‹œìŠ¤í…œì˜ ì „ë¬¸ ì„±ëŠ¥ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
- J2EE ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°ì±… ì œì‹œ
- WAS (Tomcat, WebLogic, WebSphere) ìµœì í™” ê°€ì´ë“œ
- ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ ë° íŠœë‹ ë°©ì•ˆ
- ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ í•´ì„ ë° ìž„ê³„ê°’ ì„¤ì • ê¶Œìž¥
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ê¸°ë°˜ ì´ìƒ íŒ¨í„´ íƒì§€

ì‘ë‹µ ìŠ¤íƒ€ì¼:
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±… ì œì‹œ
- ì„±ëŠ¥ ìˆ˜ì¹˜ì™€ ê·¼ê±° ë°ì´í„° ê¸°ë°˜ ë¶„ì„
- ë‹¨ê³„ë³„ í•´ê²° í”„ë¡œì„¸ìŠ¤ ì œê³µ
- í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…`
    },
    {
      name: 'AIRIS ìž¥ì•  ëŒ€ì‘ ë§¤ë‹ˆì €',
      description: 'ì‹œìŠ¤í…œ ìž¥ì•  ëŒ€ì‘ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì „ë¬¸ ì±—ë´‡',
      provider: 'openai',
      model: 'gpt-4o-mini',
      system_prompt: `ë‹¹ì‹ ì€ AIRIS EPM ì‹œìŠ¤í…œì˜ ìž¥ì•  ëŒ€ì‘ ë§¤ë‹ˆì €ìž…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
- ìž¥ì•  ìƒí™© ì‹ ì† ë¶„ì„ ë° ì‹¬ê°ë„ íŒì •
- ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì ˆì°¨ ê°€ì´ë“œ
- ë³µêµ¬ ìž‘ì—… ìš°ì„ ìˆœìœ„ ê²°ì •
- ìž¥ì•  ì›ì¸ ë¶„ì„ ë° ìž¬ë°œ ë°©ì§€ ë°©ì•ˆ
- ë¹„ìƒ ëŒ€ì‘ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì§€ì›

ì‘ë‹µ íŠ¹ì§•:
- ê¸´ê¸‰ë„ì— ë”°ë¥¸ ë‹¨ê³„ì  ëŒ€ì‘ ì ˆì°¨ ì œì‹œ
- ëª…í™•í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ê²€ì¦ í¬ì¸íŠ¸ ì œê³µ
- ì‹¤ì‹œê°„ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ
- ì˜ì‚¬ê²°ì • ì§€ì›ì„ ìœ„í•œ ê°ê´€ì  ì •ë³´ ì œê³µ`
    },
    {
      name: 'AIRIS AI ì¸ì‚¬ì´íŠ¸',
      description: 'AI ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ ì±—ë´‡',
      provider: 'openai',
      model: 'gpt-4o',
      system_prompt: `ë‹¹ì‹ ì€ AIRIS EPMì˜ AI ì¸ì‚¬ì´íŠ¸ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì‹œê³„ì—´ ë°ì´í„° íŒ¨í„´ ë¶„ì„ ë° íŠ¸ë Œë“œ ì˜ˆì¸¡
- ì´ìƒ ì§•í›„ íƒì§€ ë° ì‚¬ì „ ê²½ê³ 
- ë¹„ì¦ˆë‹ˆìŠ¤ ìž„íŒ©íŠ¸ ë¶„ì„
- ìš©ëŸ‰ ê³„íš ë° í™•ìž¥ì„± ì˜ˆì¸¡
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê²°ê³¼ í•´ì„

ë¶„ì„ ì ‘ê·¼ë²•:
- ë°ì´í„° ê¸°ë°˜ ê°ê´€ì  ë¶„ì„
- í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
- ì‹œê°ì  ì°¨íŠ¸ ë° ê·¸ëž˜í”„ í™œìš©í•œ ì„¤ëª…
- ì˜ˆì¸¡ ì‹ ë¢°ë„ ë° ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ
- ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ì‹¤ìš©ì  ê¶Œìž¥ì‚¬í•­`
    }
  ];

  for (const bot of defaultBots) {
    await pool.query(
      `INSERT INTO chatbot_configs (name, description, provider, model, system_prompt, temperature, max_tokens) 
       VALUES ($1, $2, $3, $4, $5, $6, $7)`,
      [bot.name, bot.description, bot.provider, bot.model, bot.system_prompt, 0.7, 2000]
    );
  }
  
  console.log('Default chatbots initialized');
}

// Initialize LLM client based on provider
function initializeLLMClient(provider, config) {
  try {
    switch (provider) {
      case 'openai':
        return new OpenAI({
          apiKey: config.api_key,
          baseURL: config.base_url || 'https://api.openai.com/v1'
        });
      
      case 'claude':
        return new Anthropic({
          apiKey: config.api_key,
          baseURL: config.base_url || 'https://api.anthropic.com'
        });
      
      case 'gemini':
        return new GoogleGenerativeAI(config.api_key);
      
      case 'ollama':
        return {
          baseURL: config.base_url || 'http://localhost:11434',
          apiKey: config.api_key || 'ollama'
        };
      
      default:
        throw new Error(`Unsupported provider: ${provider}`);
    }
  } catch (error) {
    console.error(`Failed to initialize ${provider} client:`, error);
    return null;
  }
}

// Get LLM response based on provider
async function getLLMResponse(provider, model, messages, config = {}) {
  const startTime = Date.now();
  let tokensUsed = 0;
  
  try {
    const apiConfig = await getApiConfig(provider);
    if (!apiConfig) {
      throw new Error(`API configuration not found for provider: ${provider}`);
    }

    const client = initializeLLMClient(provider, apiConfig);
    if (!client) {
      throw new Error(`Failed to initialize client for provider: ${provider}`);
    }

    let response;
    
    switch (provider) {
      case 'openai':
        response = await client.chat.completions.create({
          model: model,
          messages: messages,
          temperature: config.temperature || 0.7,
          max_tokens: config.max_tokens || 2000,
          stream: false
        });
        
        return {
          content: response.choices[0].message.content,
          tokensUsed: response.usage?.total_tokens || 0,
          responseTime: Date.now() - startTime
        };

      case 'claude':
        const systemMessage = messages.find(m => m.role === 'system');
        const userMessages = messages.filter(m => m.role !== 'system');
        
        response = await client.messages.create({
          model: model,
          max_tokens: config.max_tokens || 2000,
          temperature: config.temperature || 0.7,
          system: systemMessage?.content || '',
          messages: userMessages
        });
        
        return {
          content: response.content[0].text,
          tokensUsed: response.usage?.input_tokens + response.usage?.output_tokens || 0,
          responseTime: Date.now() - startTime
        };

      case 'gemini':
        const genModel = client.getGenerativeModel({ model: model });
        const prompt = messages.map(m => m.content).join('\n');
        
        response = await genModel.generateContent(prompt);
        
        return {
          content: response.response.text(),
          tokensUsed: 0, // Gemini doesn't provide token count in free tier
          responseTime: Date.now() - startTime
        };

      case 'ollama':
        response = await axios.post(`${client.baseURL}/api/generate`, {
          model: model,
          prompt: messages.map(m => `${m.role}: ${m.content}`).join('\n'),
          stream: false,
          options: {
            temperature: config.temperature || 0.7,
            num_predict: config.max_tokens || 2000
          }
        });
        
        return {
          content: response.data.response,
          tokensUsed: 0, // Ollama doesn't provide token count
          responseTime: Date.now() - startTime
        };

      default:
        throw new Error(`Unsupported provider: ${provider}`);
    }
  } catch (error) {
    console.error(`LLM API Error (${provider}):`, error);
    throw error;
  }
}

// Database helper functions
async function getApiConfig(provider) {
  try {
    const { rows } = await pool.query(
      'SELECT * FROM api_configs WHERE provider = $1 AND is_active = true',
      [provider]
    );
    return rows[0] || null;
  } catch (error) {
    console.error('Error fetching API config:', error);
    return null;
  }
}

async function getChatbotConfig(id) {
  try {
    const { rows } = await pool.query(
      'SELECT * FROM chatbot_configs WHERE id = $1 AND is_active = true',
      [id]
    );
    return rows[0] || null;
  } catch (error) {
    console.error('Error fetching chatbot config:', error);
    return null;
  }
}

// Generate enhanced system prompt with context
function generateContextualPrompt(basePrompt, contextInfo) {
  if (!contextInfo || !contextInfo.pageUrl) {
    return basePrompt;
  }

  let contextPrompt = basePrompt + '\n\ní˜„ìž¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´:\n';
  
  // Page-specific context
  if (contextInfo.pageUrl.includes('j2ee-dashboard')) {
    contextPrompt += '- í˜„ìž¬ J2EE ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ê³  ìžˆìŠµë‹ˆë‹¤\n';
    contextPrompt += '- Servlet, JSP, EJB ì„±ëŠ¥ ë©”íŠ¸ë¦­ì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n';
  } else if (contextInfo.pageUrl.includes('was-dashboard')) {
    contextPrompt += '- í˜„ìž¬ WAS ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ê³  ìžˆìŠµë‹ˆë‹¤\n';
    contextPrompt += '- Tomcat, WebLogic, WebSphere ì„±ëŠ¥ì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n';
  } else if (contextInfo.pageUrl.includes('exception-dashboard')) {
    contextPrompt += '- í˜„ìž¬ ì˜ˆì™¸ ì¶”ì  ëŒ€ì‹œë³´ë“œë¥¼ ë³´ê³  ìžˆìŠµë‹ˆë‹¤\n';
    contextPrompt += '- ì—ëŸ¬ ë¶„ì„ ë° í•´ê²°ë°©ì•ˆì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n';
  } else if (contextInfo.pageUrl.includes('topology-dashboard')) {
    contextPrompt += '- í˜„ìž¬ ì„œë¹„ìŠ¤ í† í´ë¡œì§€ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ê³  ìžˆìŠµë‹ˆë‹¤\n';
    contextPrompt += '- ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„± ë° í†µì‹  íŒ¨í„´ì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n';
  } else if (contextInfo.pageUrl.includes('alert-dashboard')) {
    contextPrompt += '- í˜„ìž¬ ì•Œë¦¼ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ê³  ìžˆìŠµë‹ˆë‹¤\n';
    contextPrompt += '- ì•Œë¦¼ ì„¤ì • ë° ìž„ê³„ê°’ ê´€ë¦¬ì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”\n';
  }

  // Add metrics context if available
  if (contextInfo.metrics) {
    contextPrompt += '\ní˜„ìž¬ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­:\n';
    if (contextInfo.metrics.responseTime) {
      contextPrompt += `- í‰ê·  ì‘ë‹µì‹œê°„: ${contextInfo.metrics.responseTime}ms\n`;
    }
    if (contextInfo.metrics.errorRate) {
      contextPrompt += `- ì—ëŸ¬ìœ¨: ${contextInfo.metrics.errorRate}%\n`;
    }
    if (contextInfo.metrics.throughput) {
      contextPrompt += `- ì²˜ë¦¬ëŸ‰: ${contextInfo.metrics.throughput} req/sec\n`;
    }
  }

  contextPrompt += '\nìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.';
  
  return contextPrompt;
}

// API Routes

// Health check
app.get('/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    service: 'airis-chatbot-api' 
  });
});

// Get all chatbot configurations
app.get('/api/chatbot/configs', async (req, res) => {
  try {
    const { rows } = await pool.query(
      'SELECT id, name, description, provider, model, is_active, created_at FROM chatbot_configs ORDER BY created_at DESC'
    );
    res.json(rows);
  } catch (error) {
    console.error('Error fetching chatbot configs:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// Get specific chatbot configuration
app.get('/api/chatbot/configs/:id', async (req, res) => {
  try {
    const { id } = req.params;
    const chatbot = await getChatbotConfig(id);
    
    if (!chatbot) {
      return res.status(404).json({ error: 'Chatbot not found' });
    }
    
    res.json(chatbot);
  } catch (error) {
    console.error('Error fetching chatbot config:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// Chat endpoint - main functionality
app.post('/api/chatbot/chat', async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { 
      chatbotId, 
      message, 
      sessionId, 
      userId = 'anonymous',
      contextInfo = {} 
    } = req.body;

    if (!chatbotId || !message || !sessionId) {
      return res.status(400).json({ 
        error: 'Missing required fields: chatbotId, message, sessionId' 
      });
    }

    // Get chatbot configuration
    const chatbot = await getChatbotConfig(chatbotId);
    if (!chatbot) {
      return res.status(404).json({ error: 'Chatbot not found' });
    }

    // Generate contextual system prompt
    const systemPrompt = generateContextualPrompt(chatbot.system_prompt, contextInfo);
    
    // Prepare messages for LLM
    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: message }
    ];

    // Get LLM response
    const llmResponse = await getLLMResponse(
      chatbot.provider, 
      chatbot.model, 
      messages,
      {
        temperature: chatbot.temperature,
        max_tokens: chatbot.max_tokens
      }
    );

    // Save chat history
    await pool.query(
      `INSERT INTO chat_history 
       (session_id, user_id, chatbot_id, user_message, bot_response, context_info, response_time_ms, tokens_used) 
       VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
      [
        sessionId, 
        userId, 
        chatbotId, 
        message, 
        llmResponse.content,
        JSON.stringify(contextInfo),
        llmResponse.responseTime,
        llmResponse.tokensUsed
      ]
    );

    // Cache response disabled temporarily
    // TODO: Re-enable Redis caching after fixing connection issues

    res.json({
      response: llmResponse.content,
      responseTime: llmResponse.responseTime,
      tokensUsed: llmResponse.tokensUsed,
      chatbotName: chatbot.name,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Chat API error:', error);
    
    const errorResponse = {
      error: 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ìž¬ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined,
      responseTime: Date.now() - startTime
    };
    
    res.status(500).json(errorResponse);
  }
});

// Get chat history for a session
app.get('/api/chatbot/history/:sessionId', async (req, res) => {
  try {
    const { sessionId } = req.params;
    const { limit = 50, offset = 0 } = req.query;
    
    const { rows } = await pool.query(
      `SELECT 
        ch.id, ch.user_message, ch.bot_response, ch.created_at, ch.response_time_ms, ch.tokens_used,
        cc.name as chatbot_name, cc.provider
       FROM chat_history ch
       JOIN chatbot_configs cc ON ch.chatbot_id = cc.id
       WHERE ch.session_id = $1
       ORDER BY ch.created_at DESC
       LIMIT $2 OFFSET $3`,
      [sessionId, limit, offset]
    );
    
    res.json(rows);
  } catch (error) {
    console.error('Error fetching chat history:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// Analytics endpoint
app.get('/api/chatbot/analytics', async (req, res) => {
  try {
    // Get basic stats
    const statsQueries = [
      'SELECT COUNT(*) as total_chats FROM chat_history WHERE created_at >= NOW() - INTERVAL \'24 hours\'',
      'SELECT COUNT(DISTINCT session_id) as active_sessions FROM chat_history WHERE created_at >= NOW() - INTERVAL \'1 hour\'',
      'SELECT AVG(response_time_ms) as avg_response_time FROM chat_history WHERE created_at >= NOW() - INTERVAL \'24 hours\'',
      'SELECT SUM(tokens_used) as total_tokens FROM chat_history WHERE created_at >= NOW() - INTERVAL \'24 hours\'',
      'SELECT COUNT(*) as active_bots FROM chatbot_configs WHERE is_active = true'
    ];
    
    const results = await Promise.all(
      statsQueries.map(query => pool.query(query))
    );
    
    const analytics = {
      totalChats: parseInt(results[0].rows[0].total_chats),
      activeSessions: parseInt(results[1].rows[0].active_sessions),
      avgResponseTime: Math.round(parseFloat(results[2].rows[0].avg_response_time) || 0),
      totalTokens: parseInt(results[3].rows[0].total_tokens) || 0,
      activeBots: parseInt(results[4].rows[0].active_bots)
    };
    
    // Get popular chatbots
    const { rows: popularBots } = await pool.query(`
      SELECT 
        cc.name, 
        COUNT(*) as usage_count,
        AVG(ch.response_time_ms) as avg_response_time
      FROM chat_history ch
      JOIN chatbot_configs cc ON ch.chatbot_id = cc.id
      WHERE ch.created_at >= NOW() - INTERVAL '24 hours'
      GROUP BY cc.id, cc.name
      ORDER BY usage_count DESC
      LIMIT 5
    `);
    
    analytics.popularChatbots = popularBots;
    
    res.json(analytics);
  } catch (error) {
    console.error('Error fetching analytics:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// API configuration management
app.get('/api/chatbot/api-configs', async (req, res) => {
  try {
    const { rows } = await pool.query(
      'SELECT provider, base_url, is_active, created_at FROM api_configs ORDER BY provider'
    );
    res.json(rows);
  } catch (error) {
    console.error('Error fetching API configs:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

app.post('/api/chatbot/api-configs', async (req, res) => {
  try {
    const { provider, apiKey, baseUrl } = req.body;
    
    if (!provider || !apiKey) {
      return res.status(400).json({ error: 'Provider and API key are required' });
    }
    
    await pool.query(
      `INSERT INTO api_configs (provider, api_key, base_url, is_active) 
       VALUES ($1, $2, $3, $4)
       ON CONFLICT (provider) 
       DO UPDATE SET api_key = $2, base_url = $3, updated_at = CURRENT_TIMESTAMP`,
      [provider, apiKey, baseUrl, true]
    );
    
    res.json({ success: true, message: 'API configuration saved successfully' });
  } catch (error) {
    console.error('Error saving API config:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// Test API connection
app.post('/api/chatbot/test-connection', async (req, res) => {
  try {
    const { provider, model } = req.body;
    
    if (!provider) {
      return res.status(400).json({ error: 'Provider is required' });
    }
    
    const testMessage = [
      { role: 'system', content: 'You are a test assistant.' },
      { role: 'user', content: 'Hello, this is a connection test.' }
    ];
    
    const response = await getLLMResponse(provider, model || 'gpt-3.5-turbo', testMessage);
    
    res.json({ 
      success: true, 
      message: 'Connection successful',
      responseTime: response.responseTime,
      tokensUsed: response.tokensUsed
    });
  } catch (error) {
    console.error('Connection test failed:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Initialize and start server
async function startServer() {
  try {
    // Skip Redis for now - TODO: Fix Redis connection issues
    console.log('âš ï¸  Redis disabled temporarily');
    
    // Try to initialize database - don't block server startup if it fails
    try {
      await initializeDatabase();
    } catch (dbError) {
      console.error('Database initialization failed, but server will continue:', dbError.message);
    }
    
    app.listen(port, () => {
      console.log(`ðŸ¤– AIRIS Chatbot API Server running on port ${port}`);
      console.log(`ðŸ“Š Health check: http://localhost:${port}/health`);
      console.log(`ðŸ’¬ Chat endpoint: http://localhost:${port}/api/chatbot/chat`);
      console.log(`ðŸ”„ Redis caching: ${redisClient ? 'enabled' : 'disabled'}`);
    });
  } catch (error) {
    console.error('Failed to start server:', error);
    process.exit(1);
  }
}

// Graceful shutdown
process.on('SIGINT', async () => {
  console.log('Shutting down gracefully...');
  
  if (redisClient) {
    try {
      await redisClient.disconnect();
      console.log('Redis disconnected');
    } catch (error) {
      console.log('Redis disconnect error:', error.message);
    }
  }
  
  try {
    await pool.end();
    console.log('Database disconnected');
  } catch (error) {
    console.log('Database disconnect error:', error.message);
  }
  
  process.exit(0);
});

startServer();

module.exports = app;