# AIRIS EPM ë°°í¬ ë° ìš´ì˜ ê°€ì´ë“œ

## ğŸ“š ëª©ì°¨

1. [ë°°í¬ í™˜ê²½ êµ¬ì„±](#ë°°í¬-í™˜ê²½-êµ¬ì„±)
2. [ì»¨í…Œì´ë„ˆí™” ë° Docker](#ì»¨í…Œì´ë„ˆí™”-ë°-docker)
3. [Kubernetes ë°°í¬](#kubernetes-ë°°í¬)
4. [CI/CD íŒŒì´í”„ë¼ì¸](#cicd-íŒŒì´í”„ë¼ì¸)
5. [ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…](#ëª¨ë‹ˆí„°ë§-ë°-ë¡œê¹…)
6. [ë³´ì•ˆ ì„¤ì •](#ë³´ì•ˆ-ì„¤ì •)
7. [ì„±ëŠ¥ íŠœë‹](#ì„±ëŠ¥-íŠœë‹)
8. [ë°±ì—… ë° ë³µêµ¬](#ë°±ì—…-ë°-ë³µêµ¬)
9. [ìš´ì˜ ì ˆì°¨](#ìš´ì˜-ì ˆì°¨)
10. [ì¥ì•  ëŒ€ì‘](#ì¥ì• -ëŒ€ì‘)

## ğŸ—ï¸ ë°°í¬ í™˜ê²½ êµ¬ì„±

### í™˜ê²½ë³„ êµ¬ì„± ì „ëµ

#### Development í™˜ê²½
```yaml
Environment: Development
Purpose: ê°œë°œ ë° ì´ˆê¸° í…ŒìŠ¤íŠ¸
Resources: ìµœì†Œ ì‚¬ì–‘
Services: All-in-one ë˜ëŠ” ë‹¨ì¼ ë…¸ë“œ
Monitoring: ê¸°ë³¸ ë ˆë²¨
Security: ê°œë°œ ì „ìš© ì„¤ì •
```

#### Staging í™˜ê²½
```yaml
Environment: Staging
Purpose: í†µí•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ê²€ì¦
Resources: í”„ë¡œë•ì…˜ì˜ 50-70%
Services: í”„ë¡œë•ì…˜ê³¼ ë™ì¼í•œ ì•„í‚¤í…ì²˜
Monitoring: í”„ë¡œë•ì…˜ ìˆ˜ì¤€
Security: í”„ë¡œë•ì…˜ê³¼ ë™ì¼
```

#### Production í™˜ê²½
```yaml
Environment: Production
Purpose: ì‹¤ì œ ì„œë¹„ìŠ¤ ìš´ì˜
Resources: ìµœì í™”ëœ ì‚¬ì–‘
Services: ê³ ê°€ìš©ì„± í´ëŸ¬ìŠ¤í„°
Monitoring: ì™„ì „í•œ ê´€ì°°ì„±
Security: ìµœê³  ë³´ì•ˆ ìˆ˜ì¤€
```

### ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­

#### ìµœì†Œ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

| ì»´í¬ë„ŒíŠ¸ | CPU | Memory | Disk | Network |
|----------|-----|---------|------|---------|
| **Metrics Service** | 2 cores | 4GB | 50GB SSD | 1Gbps |
| **Log Service** | 2 cores | 4GB | 100GB SSD | 1Gbps |
| **Trace Service** | 1 core | 2GB | 20GB SSD | 1Gbps |
| **Alert Service** | 1 core | 2GB | 20GB SSD | 1Gbps |
| **ClickHouse** | 4 cores | 8GB | 500GB SSD | 1Gbps |
| **Elasticsearch** | 4 cores | 8GB | 200GB SSD | 1Gbps |
| **Redis** | 2 cores | 4GB | 50GB SSD | 1Gbps |
| **Kafka** | 2 cores | 4GB | 100GB SSD | 1Gbps |

#### ê¶Œì¥ í”„ë¡œë•ì…˜ ì‚¬ì–‘

| ì»´í¬ë„ŒíŠ¸ | CPU | Memory | Disk | Network | Replicas |
|----------|-----|---------|------|---------|----------|
| **Metrics Service** | 4 cores | 8GB | 100GB SSD | 10Gbps | 3 |
| **Log Service** | 4 cores | 8GB | 200GB SSD | 10Gbps | 3 |
| **Trace Service** | 2 cores | 4GB | 50GB SSD | 10Gbps | 2 |
| **Alert Service** | 2 cores | 4GB | 50GB SSD | 10Gbps | 2 |
| **ClickHouse** | 8 cores | 32GB | 2TB NVMe | 10Gbps | 3 |
| **Elasticsearch** | 8 cores | 32GB | 1TB NVMe | 10Gbps | 3 |
| **Redis** | 4 cores | 16GB | 100GB SSD | 10Gbps | 2 |
| **Kafka** | 4 cores | 16GB | 500GB SSD | 10Gbps | 3 |

## ğŸ³ ì»¨í…Œì´ë„ˆí™” ë° Docker

### Docker ì´ë¯¸ì§€ ë¹Œë“œ

#### Multi-stage Dockerfile ì˜ˆì‹œ

```dockerfile
# services/metrics-service/Dockerfile
# Build stage
FROM node:18-alpine AS builder

WORKDIR /app

# Install dependencies
COPY package*.json ./
COPY ../shared/package*.json ../shared/
RUN npm ci --only=production

# Copy source
COPY src ./src
COPY ../shared/src ../shared/src
COPY tsconfig*.json ./

# Build
RUN npm run build

# Production stage  
FROM node:18-alpine AS production

# Create app user
RUN addgroup -g 1001 -S airis && \
    adduser -S airis -u 1001 -G airis

# Set working directory
WORKDIR /app

# Copy built application
COPY --from=builder --chown=airis:airis /app/dist ./dist
COPY --from=builder --chown=airis:airis /app/node_modules ./node_modules
COPY --from=builder --chown=airis:airis /app/package.json ./package.json

# Install production dependencies only
RUN npm ci --only=production && npm cache clean --force

# Create necessary directories
RUN mkdir -p logs tmp && chown airis:airis logs tmp

# Switch to non-root user
USER airis

# Expose port
EXPOSE 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD node dist/health-check.js || exit 1

# Set environment
ENV NODE_ENV=production

# Start application
CMD ["node", "dist/index.js"]
```

### Docker Compose ì„¤ì •

#### í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy-production.sh

set -e

REGISTRY="registry.airis-epm.com"
VERSION=${1:-latest}
ENVIRONMENT=${2:-production}

echo "ğŸš€ Starting AIRIS EPM deployment..."
echo "Registry: $REGISTRY"
echo "Version: $VERSION"
echo "Environment: $ENVIRONMENT"

# Build and push images
echo "ğŸ“¦ Building Docker images..."
docker build -t $REGISTRY/metrics-service:$VERSION services/metrics-service/
docker build -t $REGISTRY/log-service:$VERSION services/log-service/
docker build -t $REGISTRY/trace-service:$VERSION services/trace-service/
docker build -t $REGISTRY/alert-service:$VERSION services/alert-service/

echo "ğŸ“¤ Pushing images to registry..."
docker push $REGISTRY/metrics-service:$VERSION
docker push $REGISTRY/log-service:$VERSION
docker push $REGISTRY/trace-service:$VERSION
docker push $REGISTRY/alert-service:$VERSION

# Deploy to Kubernetes
echo "â˜¸ï¸ Deploying to Kubernetes..."
envsubst < k8s/production.yaml | kubectl apply -f -

echo "âœ… Deployment completed successfully!"
```

## â˜¸ï¸ Kubernetes ë°°í¬

### Helm Chart êµ¬ì„±

#### Chart.yaml

```yaml
apiVersion: v2
name: airis-epm
description: AIRIS EPM Microservices Platform
type: application
version: 1.0.0
appVersion: "1.0.0"
home: https://airis-epm.com
maintainers:
  - name: AIRIS Team
    email: team@airis-epm.com
dependencies:
  - name: redis
    version: 17.3.7
    repository: https://charts.bitnami.com/bitnami
    condition: redis.enabled
  - name: clickhouse
    version: 3.1.0
    repository: https://charts.bitnami.com/bitnami
    condition: clickhouse.enabled
```

#### values.yaml

```yaml
# Global settings
global:
  imageRegistry: registry.airis-epm.com
  imagePullSecrets:
    - airis-registry-secret
  storageClass: fast-ssd

# Microservices
metricsService:
  enabled: true
  image:
    repository: airis-epm/metrics-service
    tag: v1.0.0
  replicaCount: 3
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

logService:
  enabled: true
  image:
    repository: airis-epm/log-service
    tag: v1.0.0
  replicaCount: 3
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m

# Infrastructure
redis:
  enabled: true
  auth:
    enabled: true
    password: "secure_redis_password"
  master:
    persistence:
      enabled: true
      size: 20Gi

clickhouse:
  enabled: true
  auth:
    username: admin
    password: "secure_clickhouse_password"
  persistence:
    enabled: true
    size: 500Gi
    storageClass: fast-ssd

# Ingress
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
  hosts:
    - host: api.airis-epm.com
      paths:
        - path: /v1/metrics
          pathType: Prefix
          service: metrics-service
        - path: /v1/logs
          pathType: Prefix
          service: log-service
  tls:
    - secretName: airis-epm-tls
      hosts:
        - api.airis-epm.com
```

## ğŸ”„ CI/CD íŒŒì´í”„ë¼ì¸

### GitHub Actions ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/deploy.yml
name: Deploy AIRIS EPM

on:
  push:
    branches: [main]
    tags: ['v*']
  pull_request:
    branches: [main]

env:
  REGISTRY: registry.airis-epm.com
  DOCKER_BUILDKIT: 1

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [metrics-service, log-service, trace-service, alert-service]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: services/${{ matrix.service }}/package-lock.json
    
    - name: Install dependencies
      run: |
        cd services/shared && npm ci
        cd ../services/${{ matrix.service }} && npm ci
    
    - name: Run tests
      run: |
        cd services/${{ matrix.service }}
        npm run test:unit
        npm run test:integration
        npm run lint
        npm run typecheck
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: services/${{ matrix.service }}/coverage/lcov.info

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')
    strategy:
      matrix:
        service: [metrics-service, log-service, trace-service, alert-service]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Login to Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
    
    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        context: services/${{ matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'
    
    - name: Configure Kubernetes
      run: |
        echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > /tmp/kubeconfig
        export KUBECONFIG=/tmp/kubeconfig
    
    - name: Deploy to Staging
      run: |
        export KUBECONFIG=/tmp/kubeconfig
        helm upgrade --install airis-epm ./helm/airis-epm \
          --namespace airis-epm-staging \
          --create-namespace \
          --set global.environment=staging \
          --set metricsService.image.tag=${{ github.sha }} \
          --wait --timeout=10m

  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Kubectl
      uses: azure/setup-kubectl@v3
    
    - name: Deploy to Production
      run: |
        echo "${{ secrets.KUBE_CONFIG_PROD }}" | base64 -d > /tmp/kubeconfig
        export KUBECONFIG=/tmp/kubeconfig
        
        helm upgrade --install airis-epm ./helm/airis-epm \
          --namespace airis-epm \
          --create-namespace \
          --set global.environment=production \
          --set metricsService.image.tag=${GITHUB_REF#refs/tags/} \
          --wait --timeout=15m
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### Prometheus ì„¤ì •

#### ServiceMonitor

```yaml
# monitoring/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: airis-epm-services
  namespace: airis-epm
  labels:
    app: airis-epm
spec:
  selector:
    matchLabels:
      app: metrics-service
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    honorLabels: true
```

#### PrometheusRule

```yaml
# monitoring/prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: airis-epm-rules
  namespace: airis-epm
spec:
  groups:
  - name: airis-epm.rules
    rules:
    - alert: HighCPUUsage
      expr: cpu_usage_percent > 80
      for: 5m
      labels:
        severity: warning
        service: "{{ $labels.service }}"
      annotations:
        summary: "High CPU usage detected"
        description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"
    
    - alert: HighMemoryUsage
      expr: memory_usage_percent > 85
      for: 3m
      labels:
        severity: critical
        service: "{{ $labels.service }}"
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"
    
    - alert: ServiceDown
      expr: up == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Service is down"
        description: "{{ $labels.instance }} has been down for more than 1 minute"
```

## ğŸ”’ ë³´ì•ˆ ì„¤ì •

### Network Policies

```yaml
# security/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: airis-epm-network-policy
  namespace: airis-epm
spec:
  podSelector:
    matchLabels:
      app: metrics-service
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: airis-epm
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8001
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: airis-epm
    ports:
    - protocol: TCP
      port: 8500  # Consul
    - protocol: TCP
      port: 6379  # Redis
    - protocol: TCP
      port: 8123  # ClickHouse
```

## ğŸ’¾ ë°±ì—… ë° ë³µêµ¬

### ìë™í™” ë°±ì—… ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/backup-system.sh

set -e

BACKUP_DIR="/backups/$(date +%Y%m%d_%H%M%S)"
RETENTION_DAYS=30

echo "ğŸ”„ Starting AIRIS EPM system backup..."
mkdir -p $BACKUP_DIR

# ClickHouse ë°±ì—…
echo "ğŸ“Š Backing up ClickHouse..."
kubectl exec -n airis-epm clickhouse-0 -- clickhouse-client -q "
  BACKUP TABLE metrics TO S3('s3://airis-backups/clickhouse/$(date +%Y%m%d)/metrics', '${AWS_ACCESS_KEY_ID}', '${AWS_SECRET_ACCESS_KEY}')
"

# Elasticsearch ë°±ì—…
echo "ğŸ“ Backing up Elasticsearch..."
kubectl exec -n airis-epm elasticsearch-0 -- curl -X PUT "localhost:9200/_snapshot/s3_repository/$(date +%Y%m%d_%H%M%S)" -H 'Content-Type: application/json' -d'
{
  "indices": "logs-*",
  "ignore_unavailable": true,
  "include_global_state": false
}'

# Redis ë°±ì—…
echo "ğŸ’¾ Backing up Redis..."
kubectl exec -n airis-epm redis-0 -- redis-cli --rdb /tmp/dump.rdb
kubectl cp airis-epm/redis-0:/tmp/dump.rdb $BACKUP_DIR/redis-dump.rdb

# ì„¤ì • ë°±ì—…
echo "âš™ï¸ Backing up configurations..."
kubectl get configmaps -n airis-epm -o yaml > $BACKUP_DIR/configmaps.yaml
kubectl get secrets -n airis-epm -o yaml > $BACKUP_DIR/secrets.yaml

# ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find /backups -type d -mtime +$RETENTION_DAYS -exec rm -rf {} \;

echo "âœ… Backup completed: $BACKUP_DIR"
```

## ğŸš¨ ì¥ì•  ëŒ€ì‘

### ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/auto-recovery.sh

SERVICE_NAME=$1
NAMESPACE=${2:-airis-epm}

if [ -z "$SERVICE_NAME" ]; then
    echo "Usage: $0 <service-name> [namespace]"
    exit 1
fi

echo "ğŸš¨ Starting auto-recovery for $SERVICE_NAME..."

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
UNHEALTHY_PODS=$(kubectl get pods -n $NAMESPACE -l app=$SERVICE_NAME -o json | jq -r '.items[] | select(.status.phase != "Running" or (.status.containerStatuses[]?.ready != true)) | .metadata.name')

if [ -n "$UNHEALTHY_PODS" ]; then
    echo "ğŸ”§ Found unhealthy pods, restarting..."
    for pod in $UNHEALTHY_PODS; do
        kubectl delete pod $pod -n $NAMESPACE
        echo "â™»ï¸ Deleted pod: $pod"
    done
    
    # íŒŒë“œ ì¬ì‹œì‘ ëŒ€ê¸°
    kubectl wait --for=condition=ready pod -l app=$SERVICE_NAME -n $NAMESPACE --timeout=300s
fi

# 2. íŠ¸ë˜í”½ ì¬ë¶„ë°°
echo "ğŸ”„ Redistributing traffic..."
kubectl annotate service $SERVICE_NAME -n $NAMESPACE "last-restart=$(date)" --overwrite

# 3. í—¬ìŠ¤ì²´í¬ í™•ì¸
echo "ğŸ¥ Running health checks..."
SERVICE_IP=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.clusterIP}')
SERVICE_PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[0].port}')

for i in {1..5}; do
    if curl -f http://$SERVICE_IP:$SERVICE_PORT/health; then
        echo "âœ… Health check passed"
        break
    else
        echo "âŒ Health check failed, retry $i/5"
        sleep 10
    fi
done

echo "âœ… Auto-recovery completed for $SERVICE_NAME"
```

### ì¥ì•  ëŒ€ì‘ í”Œë ˆì´ë¶

#### ì„œë¹„ìŠ¤ ë‹¤ìš´ ëŒ€ì‘

```bash
# 1. ì¦‰ì‹œ í™•ì¸ì‚¬í•­
kubectl get pods -n airis-epm
kubectl get svc -n airis-epm
kubectl describe pod <failing-pod> -n airis-epm

# 2. ë¡œê·¸ ë¶„ì„
kubectl logs <pod-name> -n airis-epm --tail=100
kubectl logs <pod-name> -n airis-epm --previous

# 3. ë¦¬ì†ŒìŠ¤ í™•ì¸
kubectl top pods -n airis-epm
kubectl describe hpa -n airis-epm

# 4. íŠ¸ë˜í”½ ì°¨ë‹¨ (í•„ìš”ì‹œ)
kubectl scale deployment/<service-name> --replicas=0 -n airis-epm

# 5. ê¸´ê¸‰ ë³µêµ¬
kubectl rollout restart deployment/<service-name> -n airis-epm
kubectl rollout status deployment/<service-name> -n airis-epm
```

## ğŸ”§ ìš´ì˜ ìŠ¤í¬ë¦½íŠ¸

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}

echo "ğŸš€ Deploying AIRIS EPM to $ENVIRONMENT..."

# í™˜ê²½ë³„ ì„¤ì •
case $ENVIRONMENT in
    "development")
        NAMESPACE="airis-epm-dev"
        REPLICAS=1
        ;;
    "staging")
        NAMESPACE="airis-epm-staging" 
        REPLICAS=2
        ;;
    "production")
        NAMESPACE="airis-epm"
        REPLICAS=3
        ;;
    *)
        echo "âŒ Unknown environment: $ENVIRONMENT"
        exit 1
        ;;
esac

# Helm ë°°í¬
helm upgrade --install airis-epm ./helm/airis-epm \
    --namespace $NAMESPACE \
    --create-namespace \
    --set global.environment=$ENVIRONMENT \
    --set metricsService.replicaCount=$REPLICAS \
    --set logService.replicaCount=$REPLICAS \
    --set traceService.replicaCount=$REPLICAS \
    --set alertService.replicaCount=$REPLICAS \
    --wait --timeout=10m

echo "âœ… Deployment completed successfully!"
```

ì´ ë°°í¬ ê°€ì´ë“œëŠ” AIRIS EPM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œìŠ¤í…œì˜ í¬ê´„ì ì¸ ë°°í¬ ì „ëµê³¼ ìš´ì˜ ì ˆì°¨ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° í™˜ê²½ë³„ íŠ¹ì„±ì— ë§ëŠ” ì„¤ì •ê³¼ ìë™í™”ëœ ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ìš´ì˜ì„ ì§€ì›í•©ë‹ˆë‹¤.