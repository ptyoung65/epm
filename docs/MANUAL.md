# AIRIS EPM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ ì‚¬ìš© ë§¤ë‰´ì–¼

## ğŸ“š ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [í™˜ê²½ êµ¬ì„±](#í™˜ê²½-êµ¬ì„±)
3. [ì„œë¹„ìŠ¤ ì‹œì‘ ë° ì¤‘ì§€](#ì„œë¹„ìŠ¤-ì‹œì‘-ë°-ì¤‘ì§€)
4. [ê° ì„œë¹„ìŠ¤ ì‚¬ìš©ë²•](#ê°-ì„œë¹„ìŠ¤-ì‚¬ìš©ë²•)
5. [API ì‚¬ìš© ê°€ì´ë“œ](#api-ì‚¬ìš©-ê°€ì´ë“œ)
6. [ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…](#ëª¨ë‹ˆí„°ë§-ë°-ë””ë²„ê¹…)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
8. [ìš´ì˜ ê°€ì´ë“œ](#ìš´ì˜-ê°€ì´ë“œ)

## ğŸ¯ ì‹œìŠ¤í…œ ê°œìš”

AIRIS EPM(Enterprise Performance Monitoring)ì€ ëŒ€ê·œëª¨ ë¶„ì‚° í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ì œê³µí•˜ëŠ” ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê¸°ë°˜ í”Œë«í¼ì…ë‹ˆë‹¤.

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Service Discovery (Consul)                   â”‚
â”‚                         Port: 8500                              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”     â”Œâ”€â”€â”€â–¼â”€â”€â”€â”     â”Œâ”€â”€â”€â–¼â”€â”€â”€â”     â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
   â”‚Metricsâ”‚     â”‚  Log  â”‚     â”‚ Trace â”‚     â”‚ Alert â”‚
   â”‚Serviceâ”‚     â”‚Serviceâ”‚     â”‚Serviceâ”‚     â”‚Serviceâ”‚
   â”‚ :8001 â”‚     â”‚ :8002 â”‚     â”‚ :8003 â”‚     â”‚ :8004 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì„œë¹„ìŠ¤ë³„ ì—­í• 

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì—­í•  | ë°ì´í„° ì €ì¥ì†Œ |
|--------|------|------|--------------|
| **Metrics Service** | 8001 | ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘/ì§‘ê³„ | ClickHouse |
| **Log Service** | 8002 | êµ¬ì¡°í™”ëœ ë¡œê·¸ ì²˜ë¦¬/ê²€ìƒ‰ | Elasticsearch |
| **Trace Service** | 8003 | ë¶„ì‚° íŠ¸ë ˆì´ì‹± ìˆ˜ì§‘/ë¶„ì„ | Jaeger |
| **Alert Service** | 8004 | ì•Œë¦¼ ê·œì¹™ ê´€ë¦¬/ì „ì†¡ | Redis |

## ğŸ”§ í™˜ê²½ êµ¬ì„±

### 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­

```bash
# Docker & Docker Compose
docker --version    # >= 20.10.0
docker-compose --version  # >= 2.0.0

# Node.js (ê°œë°œì‹œ)
node --version      # >= 18.0.0
npm --version       # >= 8.0.0
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„±:

```bash
# ë³µì‚¬í•˜ì—¬ .env íŒŒì¼ë¡œ ì €ì¥
cp .env.example .env

# í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cat > .env << 'EOF'
NODE_ENV=production

# Service Discovery
CONSUL_HOST=localhost
CONSUL_PORT=8500

# Cache & Queue
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Databases
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_DATABASE=airis
CLICKHOUSE_USERNAME=admin
CLICKHOUSE_PASSWORD=admin123

ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USERNAME=
ELASTICSEARCH_PASSWORD=

# Message Bus
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=airis-epm
KAFKA_GROUP_ID=airis-consumers

# Tracing
JAEGER_ENDPOINT=http://localhost:14268/api/traces
JAEGER_SAMPLING_RATE=0.1

# Security
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
API_RATE_LIMIT=1000

# Notifications
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password

SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
SLACK_CHANNEL=#alerts

# Feature Flags
ENABLE_DISTRIBUTED_TRACING=true
ENABLE_SERVICE_MESH=false
ENABLE_AUTO_SCALING=true
EOF
```

### 3. ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸

```bash
AIRIS_EPM/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ shared/                 # ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”œâ”€â”€ metrics-service/        # ë©”íŠ¸ë¦­ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ log-service/           # ë¡œê·¸ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ trace-service/         # íŠ¸ë ˆì´ì‹± ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ alert-service/         # ì•Œë¦¼ ì„œë¹„ìŠ¤
â”‚   â””â”€â”€ service-registry/      # ì„œë¹„ìŠ¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”œâ”€â”€ docker-compose.yml         # ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”œâ”€â”€ .env                       # í™˜ê²½ ë³€ìˆ˜
â””â”€â”€ scripts/                   # ìš´ì˜ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ start-all.sh
    â”œâ”€â”€ stop-all.sh
    â””â”€â”€ health-check.sh
```

## ğŸš€ ì„œë¹„ìŠ¤ ì‹œì‘ ë° ì¤‘ì§€

### 1. ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
./scripts/start-all.sh
```

### 2. ê°œë³„ ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì‹œì‘
docker-compose up -d consul redis clickhouse elasticsearch kafka jaeger
docker-compose up -d metrics-service
docker-compose up -d log-service
docker-compose up -d trace-service
docker-compose up -d alert-service
```

### 3. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps

# ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker-compose logs -f metrics-service

# í—¬ìŠ¤ ì²´í¬
./scripts/health-check.sh

# ë˜ëŠ” ê°œë³„ í—¬ìŠ¤ ì²´í¬
curl http://localhost:8001/health
curl http://localhost:8002/health
curl http://localhost:8003/health
curl http://localhost:8004/health
```

### 4. ì„œë¹„ìŠ¤ ì¤‘ì§€

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì¤‘ì§€
docker-compose down

# ë°ì´í„°ê¹Œì§€ ì™„ì „ ì‚­ì œ
docker-compose down -v

# ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
./scripts/stop-all.sh
```

## ğŸ” ê° ì„œë¹„ìŠ¤ ì‚¬ìš©ë²•

### 1. Metrics Service (í¬íŠ¸: 8001)

#### ë©”íŠ¸ë¦­ ë°ì´í„° ì „ì†¡

```bash
# ë‹¨ì¼ ë©”íŠ¸ë¦­ ì „ì†¡
curl -X POST http://localhost:8001/metrics \
  -H "Content-Type: application/json" \
  -d '{
    "name": "cpu.usage",
    "value": 75.5,
    "timestamp": "2024-01-15T10:30:00Z",
    "labels": {
      "host": "web-server-01",
      "region": "us-east-1"
    }
  }'

# ë°°ì¹˜ ë©”íŠ¸ë¦­ ì „ì†¡
curl -X POST http://localhost:8001/metrics/batch \
  -H "Content-Type: application/json" \
  -d '{
    "metrics": [
      {
        "name": "memory.usage",
        "value": 85.2,
        "labels": {"host": "web-server-01"}
      },
      {
        "name": "disk.usage",
        "value": 45.8,
        "labels": {"host": "web-server-01", "mount": "/"}
      }
    ]
  }'
```

#### ë©”íŠ¸ë¦­ ì¡°íšŒ

```bash
# ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ
curl "http://localhost:8001/metrics/query?name=cpu.usage&from=2024-01-15T10:00:00Z&to=2024-01-15T11:00:00Z"

# ì§‘ê³„ ë°ì´í„° ì¡°íšŒ (1ë¶„ ê°„ê²©)
curl "http://localhost:8001/metrics/query?name=cpu.usage&from=2024-01-15T10:00:00Z&to=2024-01-15T11:00:00Z&interval=1m"

# ë¼ë²¨ í•„í„°ë§
curl "http://localhost:8001/metrics/query?name=cpu.usage&labels=host:web-server-01"
```

### 2. Log Service (í¬íŠ¸: 8002)

#### ë¡œê·¸ ë°ì´í„° ì „ì†¡

```bash
# êµ¬ì¡°í™”ëœ ë¡œê·¸ ì „ì†¡
curl -X POST http://localhost:8002/logs \
  -H "Content-Type: application/json" \
  -d '{
    "timestamp": "2024-01-15T10:30:00Z",
    "level": "ERROR",
    "message": "Database connection failed",
    "service": "user-api",
    "trace_id": "abc123def456",
    "span_id": "789ghi012jkl",
    "labels": {
      "component": "database",
      "operation": "connect"
    },
    "stack_trace": "Error: Connection timeout\n  at Database.connect()\n  at UserService.init()",
    "user_id": "user_12345",
    "request_id": "req_67890"
  }'

# í”Œë ˆì¸ í…ìŠ¤íŠ¸ ë¡œê·¸
curl -X POST http://localhost:8002/logs/plain \
  -H "Content-Type: text/plain" \
  -d "2024-01-15 10:30:00 ERROR [user-api] Database connection failed"
```

#### ë¡œê·¸ ê²€ìƒ‰

```bash
# í‚¤ì›Œë“œ ê²€ìƒ‰
curl "http://localhost:8002/logs/search?q=database&from=2024-01-15T10:00:00Z&to=2024-01-15T11:00:00Z"

# ë¡œê·¸ ë ˆë²¨ í•„í„°ë§
curl "http://localhost:8002/logs/search?level=ERROR&from=2024-01-15T10:00:00Z&to=2024-01-15T11:00:00Z"

# ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ì¡°íšŒ
curl "http://localhost:8002/logs/search?service=user-api&limit=100"

# ë³µí•© ê²€ìƒ‰
curl "http://localhost:8002/logs/search?q=database%20AND%20error&service=user-api&level=ERROR"
```

### 3. Trace Service (í¬íŠ¸: 8003)

#### íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° ì „ì†¡

```bash
# ìŠ¤íŒ¬ ë°ì´í„° ì „ì†¡
curl -X POST http://localhost:8003/traces \
  -H "Content-Type: application/json" \
  -d '{
    "trace_id": "abc123def456ghi789",
    "span_id": "span_001",
    "parent_span_id": null,
    "operation_name": "GET /api/users",
    "start_time": "2024-01-15T10:30:00.000Z",
    "end_time": "2024-01-15T10:30:00.250Z",
    "duration_ms": 250,
    "service_name": "user-api",
    "tags": {
      "http.method": "GET",
      "http.url": "/api/users",
      "http.status_code": 200,
      "component": "http"
    },
    "logs": [
      {
        "timestamp": "2024-01-15T10:30:00.050Z",
        "message": "Query database for users"
      }
    ]
  }'
```

#### íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ

```bash
# íŠ¸ë ˆì´ìŠ¤ IDë¡œ ì¡°íšŒ
curl "http://localhost:8003/traces/abc123def456ghi789"

# ì„œë¹„ìŠ¤ë³„ íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ
curl "http://localhost:8003/traces/search?service=user-api&from=2024-01-15T10:00:00Z&to=2024-01-15T11:00:00Z"

# ëŠë¦° íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ (500ms ì´ìƒ)
curl "http://localhost:8003/traces/search?min_duration=500ms"

# ì˜¤ë¥˜ íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ
curl "http://localhost:8003/traces/search?tags=error:true"
```

### 4. Alert Service (í¬íŠ¸: 8004)

#### ì•Œë¦¼ ê·œì¹™ ìƒì„±

```bash
# ë©”íŠ¸ë¦­ ê¸°ë°˜ ì•Œë¦¼ ê·œì¹™
curl -X POST http://localhost:8004/rules \
  -H "Content-Type: application/json" \
  -d '{
    "name": "High CPU Usage",
    "description": "Alert when CPU usage exceeds 80%",
    "conditions": {
      "metric": "cpu.usage",
      "operator": "gt",
      "threshold": 80,
      "duration": "5m"
    },
    "severity": "warning",
    "channels": ["email", "slack"],
    "enabled": true,
    "labels": {
      "team": "infrastructure",
      "environment": "production"
    }
  }'

# ë¡œê·¸ ê¸°ë°˜ ì•Œë¦¼ ê·œì¹™
curl -X POST http://localhost:8004/rules \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Database Errors",
    "description": "Alert on database connection errors",
    "conditions": {
      "log_query": "level:ERROR AND message:database",
      "count": 10,
      "duration": "1m"
    },
    "severity": "critical",
    "channels": ["email", "slack", "sms"],
    "enabled": true
  }'
```

#### ì•Œë¦¼ ì±„ë„ ì„¤ì •

```bash
# ì´ë©”ì¼ ì±„ë„ ì„¤ì •
curl -X POST http://localhost:8004/channels \
  -H "Content-Type: application/json" \
  -d '{
    "name": "email",
    "type": "email",
    "config": {
      "recipients": ["admin@company.com", "ops@company.com"],
      "subject_template": "[ALERT] {{.RuleName}} - {{.Severity}}",
      "body_template": "Alert: {{.Description}}\nTime: {{.Timestamp}}\nValue: {{.Value}}"
    },
    "enabled": true
  }'

# Slack ì±„ë„ ì„¤ì •
curl -X POST http://localhost:8004/channels \
  -H "Content-Type: application/json" \
  -d '{
    "name": "slack",
    "type": "slack",
    "config": {
      "webhook_url": "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK",
      "channel": "#alerts",
      "username": "AIRIS-EPM",
      "icon_emoji": ":warning:"
    },
    "enabled": true
  }'
```

## ğŸ“¡ API ì‚¬ìš© ê°€ì´ë“œ

### 1. ì¸ì¦

ëª¨ë“  API ìš”ì²­ì—ëŠ” JWT í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤:

```bash
# í† í° ë°œê¸‰
curl -X POST http://localhost:8001/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "admin",
    "password": "password"
  }'

# ì‘ë‹µ
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "expires_in": 3600
}

# API ìš”ì²­ì‹œ í† í° ì‚¬ìš©
curl -X GET http://localhost:8001/metrics \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
```

### 2. ê³µí†µ ì‘ë‹µ í˜•ì‹

```json
{
  "success": true,
  "data": {},
  "message": "Success",
  "timestamp": "2024-01-15T10:30:00Z",
  "request_id": "req_12345"
}

// ì˜¤ë¥˜ ì‘ë‹µ
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input data",
    "details": {
      "field": "value"
    }
  },
  "timestamp": "2024-01-15T10:30:00Z",
  "request_id": "req_12345"
}
```

### 3. í˜ì´ì§• ë° í•„í„°ë§

```bash
# í˜ì´ì§•
curl "http://localhost:8002/logs?page=1&size=50"

# ì •ë ¬
curl "http://localhost:8002/logs?sort=timestamp:desc"

# ì‹œê°„ ë²”ìœ„ í•„í„°ë§
curl "http://localhost:8001/metrics?from=2024-01-15T00:00:00Z&to=2024-01-15T23:59:59Z"

# ë³µí•© í•„í„°ë§
curl "http://localhost:8002/logs?level=ERROR&service=user-api&from=2024-01-15T10:00:00Z&limit=100"
```

### 4. ë°°ì¹˜ ì²˜ë¦¬

```bash
# ë©”íŠ¸ë¦­ ë°°ì¹˜ ì „ì†¡
curl -X POST http://localhost:8001/metrics/batch \
  -H "Content-Type: application/json" \
  -d '{
    "metrics": [
      {"name": "cpu.usage", "value": 75.5, "labels": {"host": "server-01"}},
      {"name": "memory.usage", "value": 85.2, "labels": {"host": "server-01"}},
      {"name": "disk.usage", "value": 45.8, "labels": {"host": "server-01"}}
    ]
  }'

# ë¡œê·¸ ë°°ì¹˜ ì „ì†¡
curl -X POST http://localhost:8002/logs/batch \
  -H "Content-Type: application/json" \
  -d '{
    "logs": [
      {"level": "INFO", "message": "Server started", "service": "user-api"},
      {"level": "WARN", "message": "High memory usage", "service": "user-api"},
      {"level": "ERROR", "message": "Database error", "service": "user-api"}
    ]
  }'
```

## ğŸ” ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### 1. ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§

```bash
# ì „ì²´ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬
curl http://localhost:8001/health
curl http://localhost:8002/health
curl http://localhost:8003/health
curl http://localhost:8004/health

# ìƒì„¸ í—¬ìŠ¤ ì²´í¬
curl http://localhost:8001/health/detailed

# ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ (Prometheus í˜•ì‹)
curl http://localhost:8001/metrics/prometheus
curl http://localhost:8002/metrics/prometheus
curl http://localhost:8003/metrics/prometheus
curl http://localhost:8004/metrics/prometheus
```

### 2. ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ìƒíƒœ

```bash
# Consul UI ì ‘ì†
open http://localhost:8500

# ë“±ë¡ëœ ì„œë¹„ìŠ¤ í™•ì¸
curl http://localhost:8500/v1/agent/services

# ì„œë¹„ìŠ¤ í—¬ìŠ¤ ìƒíƒœ í™•ì¸
curl http://localhost:8500/v1/health/service/metrics-service
```

### 3. ë¡œê·¸ ë¶„ì„

```bash
# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker-compose logs -f metrics-service
docker-compose logs -f log-service
docker-compose logs -f trace-service
docker-compose logs -f alert-service

# íŠ¹ì • ì‹œê°„ ë²”ìœ„ ë¡œê·¸
docker-compose logs --since="2024-01-15T10:00:00" --until="2024-01-15T11:00:00" metrics-service

# ë¡œê·¸ íŒ¨í„´ ê²€ìƒ‰
docker-compose logs metrics-service | grep ERROR
docker-compose logs metrics-service | grep "Database connection"
```

### 4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```bash
# ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker stats

# íŠ¹ì • ì»¨í…Œì´ë„ˆ ëª¨ë‹ˆí„°ë§
docker stats airis_metrics-service_1 airis_log-service_1

# ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ
netstat -tulnp | grep :8001
netstat -tulnp | grep :8002
netstat -tulnp | grep :8003
netstat -tulnp | grep :8004
```

### 5. Jaeger íŠ¸ë ˆì´ì‹± UI

```bash
# Jaeger UI ì ‘ì†
open http://localhost:16686

# íŠ¸ë ˆì´ìŠ¤ ê²€ìƒ‰ ì˜ˆì‹œ
# 1. Service: metrics-service
# 2. Operation: POST /metrics
# 3. Time Range: Last Hour
```

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### 1. ì¼ë°˜ì ì¸ ë¬¸ì œ

#### ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì§€ ì•Šì„ ë•Œ

```bash
# í¬íŠ¸ ì¶©ëŒ í™•ì¸
sudo lsof -i :8001
sudo lsof -i :8002
sudo lsof -i :8003
sudo lsof -i :8004

# í¬íŠ¸ ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
sudo kill -9 $(lsof -t -i:8001)

# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
free -h

# Docker ë¦¬ì†ŒìŠ¤ í™•ì¸
docker system df
docker system prune -f  # ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
```

#### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨

```bash
# ClickHouse ì—°ê²° í…ŒìŠ¤íŠ¸
curl "http://localhost:8123/?query=SELECT%201"

# Elasticsearch ì—°ê²° í…ŒìŠ¤íŠ¸
curl http://localhost:9200/_cluster/health

# Redis ì—°ê²° í…ŒìŠ¤íŠ¸
docker exec -it airis_redis_1 redis-cli ping

# Kafka ì—°ê²° í…ŒìŠ¤íŠ¸
docker exec -it airis_kafka_1 kafka-topics --list --bootstrap-server localhost:9092
```

#### ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ë¬¸ì œ

```bash
# Consul ìƒíƒœ í™•ì¸
curl http://localhost:8500/v1/status/leader

# ì„œë¹„ìŠ¤ ë“±ë¡ ìƒíƒœ í™•ì¸
curl http://localhost:8500/v1/agent/services

# ìˆ˜ë™ ì„œë¹„ìŠ¤ ë“±ë¡
curl -X PUT http://localhost:8500/v1/agent/service/register \
  -d '{
    "ID": "metrics-service-1",
    "Name": "metrics-service",
    "Address": "localhost",
    "Port": 8001,
    "Check": {
      "HTTP": "http://localhost:8001/health",
      "Interval": "30s"
    }
  }'
```

### 2. ì„±ëŠ¥ ë¬¸ì œ

#### ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

```bash
# ì»¨í…Œì´ë„ˆë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}"

# ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì • (docker-compose.yml)
services:
  metrics-service:
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
```

#### ë†’ì€ CPU ì‚¬ìš©ëŸ‰

```bash
# CPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
top -p $(pgrep -d, -f "metrics-service")

# í”„ë¡œíŒŒì¼ë§ í™œì„±í™”
curl -X POST http://localhost:8001/debug/profile/start
# ... ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ...
curl -X POST http://localhost:8001/debug/profile/stop
```

#### ëŠë¦° ì‘ë‹µ ì‹œê°„

```bash
# ì‘ë‹µ ì‹œê°„ ì¸¡ì •
time curl http://localhost:8001/health

# ë¶€í•˜ í…ŒìŠ¤íŠ¸
ab -n 1000 -c 10 http://localhost:8001/health

# ë˜ëŠ” wrk ì‚¬ìš©
wrk -t12 -c400 -d30s http://localhost:8001/metrics
```

### 3. ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ

#### ClickHouse ë°ì´í„° í™•ì¸

```bash
# ClickHouse í´ë¼ì´ì–¸íŠ¸ ì ‘ì†
docker exec -it airis_clickhouse_1 clickhouse-client

# í…Œì´ë¸” í™•ì¸
SHOW TABLES;

# ë©”íŠ¸ë¦­ ë°ì´í„° í™•ì¸
SELECT name, count() as total, min(timestamp), max(timestamp)
FROM metrics
GROUP BY name
ORDER BY total DESC
LIMIT 10;

# ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸
SELECT table, name, type, key
FROM system.data_skipping_indices
WHERE database = 'airis';
```

#### Elasticsearch ì¸ë±ìŠ¤ ìƒíƒœ

```bash
# ì¸ë±ìŠ¤ ëª©ë¡ í™•ì¸
curl http://localhost:9200/_cat/indices?v

# ì¸ë±ìŠ¤ í—¬ìŠ¤ ìƒíƒœ
curl http://localhost:9200/_cluster/health?level=indices

# ë¡œê·¸ ë°ì´í„° í™•ì¸
curl "http://localhost:9200/logs-*/_search?size=10&sort=@timestamp:desc"

# ì¸ë±ìŠ¤ ì„¤ì • í™•ì¸
curl http://localhost:9200/logs-2024.01/_settings?pretty
```

## ğŸš ìš´ì˜ ê°€ì´ë“œ

### 1. ì •ê¸° ì ê²€

#### ì¼ì¼ ì ê²€ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/daily-check.sh

echo "=== AIRIS EPM Daily Health Check ==="
echo "Date: $(date)"

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "\n=== Service Status ==="
docker-compose ps

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "\n=== Disk Usage ==="
df -h

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "\n=== Memory Usage ==="
free -h

# ë¡œê·¸ ì—ëŸ¬ í™•ì¸ (ìµœê·¼ 24ì‹œê°„)
echo "\n=== Recent Errors ==="
docker-compose logs --since="24h" | grep -i error | wc -l

# ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
echo "\n=== Database Health ==="
curl -s http://localhost:8123/?query=SELECT%201 && echo "ClickHouse: OK" || echo "ClickHouse: ERROR"
curl -s http://localhost:9200/_cluster/health | jq -r '.status' | sed 's/^/Elasticsearch: /'
docker exec -it airis_redis_1 redis-cli ping | sed 's/^/Redis: /'

echo "\n=== Check Complete ==="
```

#### ì£¼ê°„ ì ê²€

```bash
#!/bin/bash
# scripts/weekly-check.sh

echo "=== AIRIS EPM Weekly Maintenance ==="

# ë¡œê·¸ ë¡œí…Œì´ì…˜
docker-compose logs --since="7d" > logs/weekly-$(date +%Y%m%d).log
docker-compose logs --no-log-prefix | head -1000 > logs/recent.log

# ë°ì´í„° ì •ë¦¬
echo "Cleaning old data..."
docker exec -it airis_clickhouse_1 clickhouse-client -q "
  OPTIMIZE TABLE metrics FINAL;
  ALTER TABLE metrics DELETE WHERE date < today() - INTERVAL 30 DAY;
"

# ì¸ë±ìŠ¤ ìµœì í™”
curl -X POST "http://localhost:9200/logs-*/_forcemerge?max_num_segments=1"

# ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ í™•ì¸
docker-compose pull

echo "Weekly maintenance complete"
```

### 2. ë°±ì—… ë° ë³µêµ¬

#### ë°ì´í„° ë°±ì—…

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backup/airis-$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# ClickHouse ë°±ì—…
echo "Backing up ClickHouse..."
docker exec airis_clickhouse_1 clickhouse-client -q "
  CREATE TABLE metrics_backup AS metrics;
  INSERT INTO metrics_backup SELECT * FROM metrics;
"

# Elasticsearch ìŠ¤ëƒ…ìˆ
echo "Creating Elasticsearch snapshot..."
curl -X PUT "localhost:9200/_snapshot/backup/$(date +%Y%m%d)" -H 'Content-Type: application/json' -d'
{
  "indices": "logs-*",
  "ignore_unavailable": true,
  "include_global_state": false
}
'

# ì„¤ì • íŒŒì¼ ë°±ì—…
cp docker-compose.yml $BACKUP_DIR/
cp .env $BACKUP_DIR/
cp -r services/*/src/config $BACKUP_DIR/configs/

echo "Backup completed: $BACKUP_DIR"
```

#### ë°ì´í„° ë³µêµ¬

```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_DATE=$1
if [ -z "$BACKUP_DATE" ]; then
  echo "Usage: $0 <backup_date> (e.g., 20240115)"
  exit 1
fi

BACKUP_DIR="/backup/airis-$BACKUP_DATE"

if [ ! -d "$BACKUP_DIR" ]; then
  echo "Backup directory not found: $BACKUP_DIR"
  exit 1
fi

echo "Restoring from backup: $BACKUP_DATE"

# ì„œë¹„ìŠ¤ ì¤‘ì§€
docker-compose down

# ì„¤ì • íŒŒì¼ ë³µì›
cp $BACKUP_DIR/docker-compose.yml ./
cp $BACKUP_DIR/.env ./

# ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ë°ì´í„° ë³µì› ëŒ€ê¸°
sleep 30

# Elasticsearch ë³µì›
curl -X POST "localhost:9200/_snapshot/backup/$BACKUP_DATE/_restore" -H 'Content-Type: application/json' -d'
{
  "indices": "logs-*",
  "ignore_unavailable": true
}
'

echo "Restore completed"
```

### 3. í™•ì¥ì„± ê´€ë¦¬

#### ìë™ ìŠ¤ì¼€ì¼ë§ ì„¤ì •

```yaml
# docker-compose.override.yml (í”„ë¡œë•ì…˜ìš©)
version: '3.8'

services:
  metrics-service:
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 60s
        max_failure_ratio: 0.3

  log-service:
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
```

#### ë¡œë“œë°¸ëŸ°ì‹± ì„¤ì •

```bash
# nginx.conf
upstream metrics_backend {
    server localhost:8001;
    server localhost:8011;  # ì¶”ê°€ ì¸ìŠ¤í„´ìŠ¤
    server localhost:8021;  # ì¶”ê°€ ì¸ìŠ¤í„´ìŠ¤
}

server {
    listen 80;
    location /metrics {
        proxy_pass http://metrics_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

### 4. ë³´ì•ˆ ê´€ë¦¬

#### SSL/TLS ì„¤ì •

```bash
# Let's Encrypt ì¸ì¦ì„œ ìƒì„±
certbot certonly --standalone -d airis.yourdomain.com

# nginx SSL ì„¤ì •
server {
    listen 443 ssl http2;
    ssl_certificate /etc/letsencrypt/live/airis.yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/airis.yourdomain.com/privkey.pem;
    
    location / {
        proxy_pass http://localhost:8001;
        proxy_ssl_verify off;
    }
}
```

#### ë°©í™”ë²½ ì„¤ì •

```bash
# UFW ë°©í™”ë²½ ì„¤ì •
sudo ufw allow 22/tcp      # SSH
sudo ufw allow 80/tcp      # HTTP
sudo ufw allow 443/tcp     # HTTPS
sudo ufw allow 8500/tcp    # Consul (ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ë§Œ)
sudo ufw enable
```

### 5. ì„±ëŠ¥ íŠœë‹

#### ClickHouse ìµœì í™”

```sql
-- clickhouse-config.xml ì„¤ì •
<clickhouse>
    <max_connections>1000</max_connections>
    <max_concurrent_queries>100</max_concurrent_queries>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>
    
    <merge_tree>
        <max_suspicious_broken_parts>100</max_suspicious_broken_parts>
        <parts_to_delay_insert>150</parts_to_delay_insert>
        <parts_to_throw_insert>300</parts_to_throw_insert>
        <max_delay_to_insert>1</max_delay_to_insert>
    </merge_tree>
</clickhouse>
```

#### Elasticsearch ìµœì í™”

```json
{
  "persistent": {
    "cluster.routing.allocation.disk.threshold.enabled": true,
    "cluster.routing.allocation.disk.watermark.low": "85%",
    "cluster.routing.allocation.disk.watermark.high": "90%",
    "cluster.routing.allocation.disk.watermark.flood_stage": "95%",
    "indices.fielddata.cache.size": "40%",
    "indices.queries.cache.size": "10%",
    "indices.requests.cache.size": "2%"
  }
}
```

ì´ ë§¤ë‰´ì–¼ì€ AIRIS EPM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì‹œìŠ¤í…œì˜ ì™„ì „í•œ ì‚¬ìš©ë²•ê³¼ ìš´ì˜ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì—¬ ì‹œìŠ¤í…œì„ íš¨ìœ¨ì ìœ¼ë¡œ ìš´ì˜í•˜ê³  ê´€ë¦¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.